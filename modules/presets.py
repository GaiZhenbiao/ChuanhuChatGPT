# -*- coding:utf-8 -*-
import os
from pathlib import Path
import gradio as gr
from .webui_locale import I18nAuto

i18n = I18nAuto()  # internationalization

CHATGLM_MODEL = None
CHATGLM_TOKENIZER = None
LLAMA_MODEL = None
LLAMA_INFERENCER = None

# ChatGPT è®¾ç½®
INITIAL_SYSTEM_PROMPT = "You are a helpful assistant."
API_HOST = "api.openai.com"
OPENAI_API_BASE = "https://api.openai.com/v1"
CHAT_COMPLETION_URL = "https://api.openai.com/v1/chat/completions"
IMAGES_COMPLETION_URL = "https://api.openai.com/v1/images/generations"
COMPLETION_URL = "https://api.openai.com/v1/completions"
BALANCE_API_URL="https://api.openai.com/dashboard/billing/credit_grants"
USAGE_API_URL="https://api.openai.com/dashboard/billing/usage"
HISTORY_DIR = Path("history")
HISTORY_DIR = "history"
TEMPLATES_DIR = "templates"

# é”™è¯¯ä¿¡æ¯
STANDARD_ERROR_MSG = i18n("â˜¹ï¸å‘ç”Ÿäº†é”™è¯¯ï¼š")  # é”™è¯¯ä¿¡æ¯çš„æ ‡å‡†å‰ç¼€
GENERAL_ERROR_MSG = i18n("è·å–å¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—")
ERROR_RETRIEVE_MSG = i18n("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–è€…API-Keyæ˜¯å¦æœ‰æ•ˆã€‚")
CONNECTION_TIMEOUT_MSG = i18n("è¿æ¥è¶…æ—¶ï¼Œæ— æ³•è·å–å¯¹è¯ã€‚")  # è¿æ¥è¶…æ—¶
READ_TIMEOUT_MSG = i18n("è¯»å–è¶…æ—¶ï¼Œæ— æ³•è·å–å¯¹è¯ã€‚")  # è¯»å–è¶…æ—¶
PROXY_ERROR_MSG = i18n("ä»£ç†é”™è¯¯ï¼Œæ— æ³•è·å–å¯¹è¯ã€‚")  # ä»£ç†é”™è¯¯
SSL_ERROR_PROMPT = i18n("SSLé”™è¯¯ï¼Œæ— æ³•è·å–å¯¹è¯ã€‚")  # SSL é”™è¯¯
NO_APIKEY_MSG = i18n("API keyä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ˜¯å¦è¾“å…¥æ­£ç¡®ã€‚")  # API key é•¿åº¦ä¸è¶³ 51 ä½
NO_INPUT_MSG = i18n("è¯·è¾“å…¥å¯¹è¯å†…å®¹ã€‚")  # æœªè¾“å…¥å¯¹è¯å†…å®¹
BILLING_NOT_APPLICABLE_MSG = i18n("è´¦å•ä¿¡æ¯ä¸é€‚ç”¨") # æœ¬åœ°è¿è¡Œçš„æ¨¡å‹è¿”å›çš„è´¦å•ä¿¡æ¯

TIMEOUT_STREAMING = 60  # æµå¼å¯¹è¯æ—¶çš„è¶…æ—¶æ—¶é—´
TIMEOUT_ALL = 200  # éæµå¼å¯¹è¯æ—¶çš„è¶…æ—¶æ—¶é—´
ENABLE_STREAMING_OPTION = True  # æ˜¯å¦å¯ç”¨é€‰æ‹©é€‰æ‹©æ˜¯å¦å®æ—¶æ˜¾ç¤ºå›ç­”çš„å‹¾é€‰æ¡†
ENABLE_LLM_NAME_CHAT_OPTION = True  # æ˜¯å¦å¯ç”¨é€‰æ‹©æ˜¯å¦ä½¿ç”¨LLMæ¨¡å‹çš„å‹¾é€‰æ¡†
CONCURRENT_COUNT = 100 # å…è®¸åŒæ—¶ä½¿ç”¨çš„ç”¨æˆ·æ•°é‡

SIM_K = 5
INDEX_QUERY_TEMPRATURE = 1.0

CHUANHU_TITLE = i18n("å·è™Chat ğŸš€")

CHUANHU_DESCRIPTION = i18n("ç”±Bilibili [åœŸå·è™è™è™](https://space.bilibili.com/29125536)ã€[æ˜æ˜­MZhao](https://space.bilibili.com/24807452) å’Œ [Keldos](https://github.com/Keldos-Li) å¼€å‘<br />è®¿é—®å·è™Chatçš„ [GitHubé¡¹ç›®](https://github.com/GaiZhenbiao/ChuanhuChatGPT) ä¸‹è½½æœ€æ–°ç‰ˆè„šæœ¬")


ONLINE_MODELS = [
    "GPT3.5 Turbo",
    "GPT3.5 Turbo Instruct",
    "GPT3.5 Turbo 16K",
    "GPT3.5 Turbo 0301",
    "GPT3.5 Turbo 0613",
    "GPT3.5 Turbo 1106",
    "GPT4",
    "GPT4 32K",
    "GPT4 Turbo",
    "GPT4 Vision",
    "å·è™åŠ©ç†",
    "å·è™åŠ©ç† Pro",
    "DALL-E 3",
    "GooglePaLM",
    "xmchat",
    "Azure OpenAI",
    "yuanai-1.0-base_10B",
    "yuanai-1.0-translate",
    "yuanai-1.0-dialog",
    "yuanai-1.0-rhythm_poems",
    "minimax-abab5-chat",
    "midjourney",
    "è®¯é£æ˜Ÿç«å¤§æ¨¡å‹V3.0",
    "è®¯é£æ˜Ÿç«å¤§æ¨¡å‹V2.0",
    "è®¯é£æ˜Ÿç«å¤§æ¨¡å‹V1.5",
    "Claude",
    "ERNIE-Bot-turbo",
    "ERNIE-Bot",
    "ERNIE-Bot-4",
]

LOCAL_MODELS = [
    "chatglm-6b",
    "chatglm-6b-int4",
    "chatglm-6b-int4-ge",
    "chatglm2-6b",
    "chatglm2-6b-int4",
    "chatglm3-6b",
    "chatglm3-6b-32k",
    "StableLM",
    "MOSS",
    "Llama-2-7B-Chat",
    "Qwen 7B",
    "Qwen 14B"
]

# Additional metadata for online and local models
MODEL_METADATA = {
    "Llama-2-7B":{
        "repo_id": "TheBloke/Llama-2-7B-GGUF",
        "filelist": ["llama-2-7b.Q6_K.gguf"],
    },
    "Llama-2-7B-Chat":{
        "repo_id": "TheBloke/Llama-2-7b-Chat-GGUF",
        "filelist": ["llama-2-7b-chat.Q6_K.gguf"],
    },
    "Qwen 7B": {
        "repo_id": "Qwen/Qwen-7B-Chat-Int4",
    },
    "Qwen 14B": {
        "repo_id": "Qwen/Qwen-14B-Chat-Int4",
    },
    "GPT3.5 Turbo": {
        "model_name": "gpt-3.5-turbo",
        "token_limit": 4096,
    },
    "GPT3.5 Turbo Instruct": {
        "model_name": "gpt-3.5-turbo-instruct",
        "token_limit": 4096,
    },
    "GPT3.5 Turbo 16K": {
        "model_name": "gpt-3.5-turbo-16k",
        "token_limit": 16384,
    },
    "GPT3.5 Turbo 0301": {
        "model_name": "gpt-3.5-turbo-0301",
        "token_limit": 4096,
    },
    "GPT3.5 Turbo 0613": {
        "model_name": "gpt-3.5-turbo-0613",
        "token_limit": 4096,
    },
    "GPT3.5 Turbo 1106": {
    "model_name": "gpt-3.5-turbo-1106",
    "token_limit": 16384,
    },
    "GPT4": {
        "model_name": "gpt-4",
        "token_limit": 8192,
    },
    "GPT4 32K": {
        "model_name": "gpt-4-32k",
        "token_limit": 32768,
    },
    "GPT4 Turbo": {
        "model_name": "gpt-4-1106-preview",
        "token_limit": 128000,
    },
    "GPT4 Vision": {
        "model_name": "gpt-4-vision-preview",
        "token_limit": 128000,
    },
    "Claude": {
        "model_name": "Claude",
        "token_limit": 4096,
    },
    "ERNIE-Bot-turbo": {
        "model_name": "ERNIE-Bot-turbo",
        "token_limit": 1024,
    },
    "ERNIE-Bot": {
        "model_name": "ERNIE-Bot",
        "token_limit": 1024,
    },
    "ERNIE-Bot-4": {
        "model_name": "ERNIE-Bot-4",
        "token_limit": 1024,
    },
}

if os.environ.get('HIDE_LOCAL_MODELS', 'false') == 'true':
    MODELS = ONLINE_MODELS
else:
    MODELS = ONLINE_MODELS + LOCAL_MODELS

DEFAULT_MODEL = 0

os.makedirs("models", exist_ok=True)
os.makedirs("lora", exist_ok=True)
os.makedirs("history", exist_ok=True)
for dir_name in os.listdir("models"):
    if os.path.isdir(os.path.join("models", dir_name)):
        if dir_name not in MODELS:
            MODELS.append(dir_name)

TOKEN_OFFSET = 1000 # æ¨¡å‹çš„tokenä¸Šé™å‡å»è¿™ä¸ªå€¼ï¼Œå¾—åˆ°è½¯ä¸Šé™ã€‚åˆ°è¾¾è½¯ä¸Šé™ä¹‹åï¼Œè‡ªåŠ¨å°è¯•å‡å°‘tokenå ç”¨ã€‚
DEFAULT_TOKEN_LIMIT = 3000 # é»˜è®¤çš„tokenä¸Šé™
REDUCE_TOKEN_FACTOR = 0.5 # ä¸æ¨¡å‹tokenä¸Šé™æƒ³ä¹˜ï¼Œå¾—åˆ°ç›®æ ‡tokenæ•°ã€‚å‡å°‘tokenå ç”¨æ—¶ï¼Œå°†tokenå ç”¨å‡å°‘åˆ°ç›®æ ‡tokenæ•°ä»¥ä¸‹ã€‚

REPLY_LANGUAGES = [
    "ç®€ä½“ä¸­æ–‡",
    "ç¹é«”ä¸­æ–‡",
    "English",
    "æ—¥æœ¬èª",
    "EspaÃ±ol",
    "FranÃ§ais",
    "Russian",
    "Deutsch",
    "í•œêµ­ì–´",
    "è·Ÿéšé—®é¢˜è¯­è¨€ï¼ˆä¸ç¨³å®šï¼‰"
]

HISTORY_NAME_METHODS = [
    i18n("æ ¹æ®æ—¥æœŸæ—¶é—´"),
    i18n("ç¬¬ä¸€æ¡æé—®"),
    i18n("æ¨¡å‹è‡ªåŠ¨æ€»ç»“ï¼ˆæ¶ˆè€—tokensï¼‰"),
]


WEBSEARCH_PTOMPT_TEMPLATE = """\
Web search results:

{web_results}
Current date: {current_date}

Instructions: Using the provided web search results, write a comprehensive reply to the given query. Make sure to cite results using [[number](URL)] notation after the reference. If the provided search results refer to multiple subjects with the same name, write separate answers for each subject.
Query: {query}
Reply in {reply_language}
"""

PROMPT_TEMPLATE = """\
Context information is below.
---------------------
{context_str}
---------------------
Current date: {current_date}.
Using the provided context information, write a comprehensive reply to the given query.
Make sure to cite results using [number] notation after the reference.
If the provided context information refer to multiple subjects with the same name, write separate answers for each subject.
Use prior knowledge only if the given context didn't provide enough information.
Answer the question: {query_str}
Reply in {reply_language}
"""

REFINE_TEMPLATE = """\
The original question is as follows: {query_str}
We have provided an existing answer: {existing_answer}
We have the opportunity to refine the existing answer
(only if needed) with some more context below.
------------
{context_msg}
------------
Given the new context, refine the original answer to better
Reply in {reply_language}
If the context isn't useful, return the original answer.
"""

SUMMARIZE_PROMPT = """Write a concise summary of the following:

{text}

CONCISE SUMMARY IN ä¸­æ–‡:"""

SUMMARY_CHAT_SYSTEM_PROMPT = """\
Please summarize the following conversation for a chat topic.
No more than 16 characters.
No special characters.
Punctuation mark is banned.
Not including '.' ':' '?' '!' 'â€œ' '*' '<' '>'.
Reply in user's language.
"""

ALREADY_CONVERTED_MARK = "<!-- ALREADY CONVERTED BY PARSER. -->"
START_OF_OUTPUT_MARK = "<!-- SOO IN MESSAGE -->"
END_OF_OUTPUT_MARK = "<!-- EOO IN MESSAGE -->"

small_and_beautiful_theme = gr.themes.Soft(
        primary_hue=gr.themes.Color(
            c50="#EBFAF2",
            c100="#CFF3E1",
            c200="#A8EAC8",
            c300="#77DEA9",
            c400="#3FD086",
            c500="#02C160",
            c600="#06AE56",
            c700="#05974E",
            c800="#057F45",
            c900="#04673D",
            c950="#2E5541",
            name="small_and_beautiful",
        ),
        secondary_hue=gr.themes.Color(
            c50="#576b95",
            c100="#576b95",
            c200="#576b95",
            c300="#576b95",
            c400="#576b95",
            c500="#576b95",
            c600="#576b95",
            c700="#576b95",
            c800="#576b95",
            c900="#576b95",
            c950="#576b95",
        ),
        neutral_hue=gr.themes.Color(
            name="gray",
            c50="#f6f7f8",
            # c100="#f3f4f6",
            c100="#F2F2F2",
            c200="#e5e7eb",
            c300="#d1d5db",
            c400="#B2B2B2",
            c500="#808080",
            c600="#636363",
            c700="#515151",
            c800="#393939",
            # c900="#272727",
            c900="#2B2B2B",
            c950="#171717",
        ),
        radius_size=gr.themes.sizes.radius_sm,
    ).set(
        # button_primary_background_fill="*primary_500",
        button_primary_background_fill_dark="*primary_600",
        # button_primary_background_fill_hover="*primary_400",
        # button_primary_border_color="*primary_500",
        button_primary_border_color_dark="*primary_600",
        button_primary_text_color="white",
        button_primary_text_color_dark="white",
        button_secondary_background_fill="*neutral_100",
        button_secondary_background_fill_hover="*neutral_50",
        button_secondary_background_fill_dark="*neutral_900",
        button_secondary_text_color="*neutral_800",
        button_secondary_text_color_dark="white",
        # background_fill_primary="#F7F7F7",
        # background_fill_primary_dark="#1F1F1F",
        # block_title_text_color="*primary_500",
        block_title_background_fill_dark="*primary_900",
        block_label_background_fill_dark="*primary_900",
        input_background_fill="#F6F6F6",
        # chatbot_code_background_color="*neutral_950",
        # gradio ä¼šæŠŠè¿™ä¸ªå‡ ä¸ªchatbotæ‰“å¤´çš„å˜é‡åº”ç”¨åˆ°å…¶ä»–mdæ¸²æŸ“çš„åœ°æ–¹ï¼Œé¬¼æ™“å¾—æ€ä¹ˆæƒ³çš„ã€‚ã€‚ã€‚
        chatbot_code_background_color_dark="*neutral_950",
    )
