# -*- coding:utf-8 -*-
import os
import logging
import sys

import gradio as gr

from modules.utils import *
from modules.presets import *
from modules.overwrites import *
from modules.chat_func import *

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s",
)

my_api_key = ""  # åœ¨è¿™é‡Œè¾“å…¥ä½ çš„ API å¯†é’¥

# if we are running in Docker
if os.environ.get("dockerrun") == "yes":
    dockerflag = True
else:
    dockerflag = False

authflag = False

if dockerflag:
    my_api_key = os.environ.get("my_api_key")
    if my_api_key == "empty":
        logging.error("Please give a api key!")
        sys.exit(1)
    # auth
    username = os.environ.get("USERNAME")
    password = os.environ.get("PASSWORD")
    if not (isinstance(username, type(None)) or isinstance(password, type(None))):
        authflag = True
else:
    if (
        not my_api_key
        and os.path.exists("api_key.txt")
        and os.path.getsize("api_key.txt")
    ):
        with open("api_key.txt", "r") as f:
            my_api_key = f.read().strip()
    if os.path.exists("auth.json"):
        with open("auth.json", "r", encoding='utf-8') as f:
            auth = json.load(f)
            username = auth["username"]
            password = auth["password"]
            if username != "" and password != "":
                authflag = True

gr.Chatbot.postprocess = postprocess
PromptHelper.compact_text_chunks = compact_text_chunks

with open("assets/custom.css", "r", encoding="utf-8") as f:
    customCSS = f.read()

with gr.Blocks(css=customCSS, theme=small_and_beautiful_theme) as demo:
    history = gr.State([])
    token_count = gr.State([])
    promptTemplates = gr.State(load_template(get_template_names(plain=True)[0], mode=2))
    user_api_key = gr.State(my_api_key)
    user_question = gr.State("")
    outputing = gr.State(False)
    topic = gr.State("æœªå‘½åå¯¹è¯å†å²è®°å½•")

    with gr.Row():
        gr.HTML(title)
        status_display = gr.Markdown(get_geoip(), elem_id="status_display")

    with gr.Row(scale=1).style(equal_height=True):
        with gr.Column(scale=5):
            with gr.Row(scale=1):
                chatbot = gr.Chatbot(elem_id="chuanhu_chatbot").style(height="100%")
            with gr.Row(scale=1):
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False, placeholder="åœ¨è¿™é‡Œè¾“å…¥"
                    ).style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                    cancelBtn = gr.Button("å–æ¶ˆ", variant="secondary", visible=False)
            with gr.Row(scale=1):
                emptyBtn = gr.Button(
                    "ğŸ§¹ æ–°çš„å¯¹è¯",
                )
                retryBtn = gr.Button("ğŸ”„ é‡æ–°ç”Ÿæˆ")
                delLastBtn = gr.Button("ğŸ—‘ï¸ åˆ é™¤ä¸€æ¡å¯¹è¯")
                reduceTokenBtn = gr.Button("â™»ï¸ æ€»ç»“å¯¹è¯")

        with gr.Column():
            with gr.Column(min_width=50, scale=1):
                with gr.Tab(label="ChatGPT"):
                    keyTxt = gr.Textbox(
                        show_label=True,
                        placeholder=f"OpenAI API-key...",
                        value=hide_middle_chars(my_api_key),
                        type="password",
                        visible=not HIDE_MY_KEY,
                        label="API-Key",
                    )
                    model_select_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹", choices=MODELS, multiselect=False, value=MODELS[0]
                    )
                    use_streaming_checkbox = gr.Checkbox(
                        label="å®æ—¶ä¼ è¾“å›ç­”", value=True, visible=enable_streaming_option
                    )
                    use_websearch_checkbox = gr.Checkbox(label="ä½¿ç”¨åœ¨çº¿æœç´¢", value=False)
                    language_select_dropdown = gr.Dropdown(
                        label="é€‰æ‹©å›å¤è¯­è¨€ï¼ˆé’ˆå¯¹æœç´¢&ç´¢å¼•åŠŸèƒ½ï¼‰",
                        choices=REPLY_LANGUAGES,
                        multiselect=False,
                        value=REPLY_LANGUAGES[0],
                    )
                    index_files = gr.Files(label="ä¸Šä¼ ç´¢å¼•æ–‡ä»¶", type="file", multiple=True)

                with gr.Tab(label="Prompt"):
                    systemPromptTxt = gr.Textbox(
                        show_label=True,
                        placeholder=f"åœ¨è¿™é‡Œè¾“å…¥System Prompt...",
                        label="System prompt",
                        value=initial_prompt,
                        lines=10,
                    ).style(container=False)
                    with gr.Accordion(label="åŠ è½½Promptæ¨¡æ¿", open=True):
                        with gr.Column():
                            with gr.Row():
                                with gr.Column(scale=6):
                                    templateFileSelectDropdown = gr.Dropdown(
                                        label="é€‰æ‹©Promptæ¨¡æ¿é›†åˆæ–‡ä»¶",
                                        choices=get_template_names(plain=True),
                                        multiselect=False,
                                        value=get_template_names(plain=True)[0],
                                    ).style(container=False)
                                with gr.Column(scale=1):
                                    templateRefreshBtn = gr.Button("ğŸ”„ åˆ·æ–°")
                            with gr.Row():
                                with gr.Column():
                                    templateSelectDropdown = gr.Dropdown(
                                        label="ä»Promptæ¨¡æ¿ä¸­åŠ è½½",
                                        choices=load_template(
                                            get_template_names(plain=True)[0], mode=1
                                        ),
                                        multiselect=False,
                                        value=load_template(
                                            get_template_names(plain=True)[0], mode=1
                                        )[0],
                                    ).style(container=False)

                with gr.Tab(label="ä¿å­˜/åŠ è½½"):
                    with gr.Accordion(label="ä¿å­˜/åŠ è½½å¯¹è¯å†å²è®°å½•", open=True):
                        with gr.Column():
                            with gr.Row():
                                with gr.Column(scale=6):
                                    historyFileSelectDropdown = gr.Dropdown(
                                        label="ä»åˆ—è¡¨ä¸­åŠ è½½å¯¹è¯",
                                        choices=get_history_names(plain=True),
                                        multiselect=False,
                                        value=get_history_names(plain=True)[0],
                                    )
                                with gr.Column(scale=1):
                                    historyRefreshBtn = gr.Button("ğŸ”„ åˆ·æ–°")
                            with gr.Row():
                                with gr.Column(scale=6):
                                    saveFileName = gr.Textbox(
                                        show_label=True,
                                        placeholder=f"è®¾ç½®æ–‡ä»¶å: é»˜è®¤ä¸º.jsonï¼Œå¯é€‰ä¸º.md",
                                        label="è®¾ç½®ä¿å­˜æ–‡ä»¶å",
                                        value="å¯¹è¯å†å²è®°å½•",
                                    ).style(container=True)
                                with gr.Column(scale=1):
                                    saveHistoryBtn = gr.Button("ğŸ’¾ ä¿å­˜å¯¹è¯")
                                    exportMarkdownBtn = gr.Button("ğŸ“ å¯¼å‡ºä¸ºMarkdown")
                                    gr.Markdown("é»˜è®¤ä¿å­˜äºhistoryæ–‡ä»¶å¤¹")
                            with gr.Row():
                                with gr.Column():
                                    downloadFile = gr.File(interactive=True)

                with gr.Tab(label="é«˜çº§"):
                    default_btn = gr.Button("ğŸ”™ æ¢å¤é»˜è®¤è®¾ç½®")
                    gr.Markdown("# âš ï¸ åŠ¡å¿…è°¨æ…æ›´æ”¹ âš ï¸\n\nå¦‚æœæ— æ³•ä½¿ç”¨è¯·æ¢å¤é»˜è®¤è®¾ç½®")

                    with gr.Accordion("å‚æ•°", open=False):
                        top_p = gr.Slider(
                            minimum=-0,
                            maximum=1.0,
                            value=1.0,
                            step=0.05,
                            interactive=True,
                            label="Top-p",
                        )
                        temperature = gr.Slider(
                            minimum=-0,
                            maximum=2.0,
                            value=1.0,
                            step=0.1,
                            interactive=True,
                            label="Temperature",
                        )

                    apiurlTxt = gr.Textbox(
                        show_label=True,
                        placeholder=f"åœ¨è¿™é‡Œè¾“å…¥APIåœ°å€...",
                        label="APIåœ°å€",
                        value="https://api.openai.com/v1/chat/completions",
                        lines=2,
                    )
                    changeAPIURLBtn = gr.Button("ğŸ”„ åˆ‡æ¢APIåœ°å€")
                    proxyTxt = gr.Textbox(
                        show_label=True,
                        placeholder=f"åœ¨è¿™é‡Œè¾“å…¥ä»£ç†åœ°å€...",
                        label="ä»£ç†åœ°å€ï¼ˆç¤ºä¾‹ï¼šhttp://127.0.0.1:10809ï¼‰",
                        value="",
                        lines=2,
                    )
                    changeProxyBtn = gr.Button("ğŸ”„ è®¾ç½®ä»£ç†åœ°å€")

    gr.Markdown(description)

    chatgpt_predict_args = dict(
        fn=predict,
        inputs=[
            user_api_key,
            systemPromptTxt,
            history,
            user_question,
            chatbot,
            token_count,
            top_p,
            temperature,
            use_streaming_checkbox,
            model_select_dropdown,
            use_websearch_checkbox,
            index_files,
            language_select_dropdown,
        ],
        outputs=[chatbot, history, status_display, token_count],
        show_progress=True,
    )

    start_outputing_args = dict(
        fn=start_outputing,
        inputs=[],
        outputs=[submitBtn, cancelBtn],
        show_progress=True,
    )

    end_outputing_args = dict(
        fn=end_outputing, inputs=[], outputs=[submitBtn, cancelBtn]
    )

    reset_textbox_args = dict(
        fn=reset_textbox, inputs=[], outputs=[user_input]
    )

    transfer_input_args = dict(
        fn=transfer_input, inputs=[user_input], outputs=[user_question, user_input, submitBtn, cancelBtn], show_progress=True
    )

    keyTxt.submit(submit_key, keyTxt, [user_api_key, status_display])
    keyTxt.change(submit_key, keyTxt, [user_api_key, status_display])
    # Chatbot
    cancelBtn.click(cancel_outputing, [], [])

    user_input.submit(**transfer_input_args).then(**chatgpt_predict_args).then(**end_outputing_args)

    submitBtn.click(**transfer_input_args).then(**chatgpt_predict_args).then(**end_outputing_args)

    emptyBtn.click(
        reset_state,
        outputs=[chatbot, history, token_count, status_display],
        show_progress=True,
    )
    emptyBtn.click(**reset_textbox_args)

    retryBtn.click(**start_outputing_args).then(
        retry,
        [
            user_api_key,
            systemPromptTxt,
            history,
            chatbot,
            token_count,
            top_p,
            temperature,
            use_streaming_checkbox,
            model_select_dropdown,
            language_select_dropdown,
        ],
        [chatbot, history, status_display, token_count],
        show_progress=True,
    ).then(**end_outputing_args)

    delLastBtn.click(
        delete_last_conversation,
        [chatbot, history, token_count],
        [chatbot, history, token_count, status_display],
        show_progress=True,
    )

    reduceTokenBtn.click(
        reduce_token_size,
        [
            user_api_key,
            systemPromptTxt,
            history,
            chatbot,
            token_count,
            top_p,
            temperature,
            gr.State(0),
            model_select_dropdown,
            language_select_dropdown,
        ],
        [chatbot, history, status_display, token_count],
        show_progress=True,
    )

    # Template
    templateRefreshBtn.click(get_template_names, None, [templateFileSelectDropdown])
    templateFileSelectDropdown.change(
        load_template,
        [templateFileSelectDropdown],
        [promptTemplates, templateSelectDropdown],
        show_progress=True,
    )
    templateSelectDropdown.change(
        get_template_content,
        [promptTemplates, templateSelectDropdown, systemPromptTxt],
        [systemPromptTxt],
        show_progress=True,
    )

    # S&L
    saveHistoryBtn.click(
        save_chat_history,
        [saveFileName, systemPromptTxt, history, chatbot],
        downloadFile,
        show_progress=True,
    )
    saveHistoryBtn.click(get_history_names, None, [historyFileSelectDropdown])
    exportMarkdownBtn.click(
        export_markdown,
        [saveFileName, systemPromptTxt, history, chatbot],
        downloadFile,
        show_progress=True,
    )
    historyRefreshBtn.click(get_history_names, None, [historyFileSelectDropdown])
    historyFileSelectDropdown.change(
        load_chat_history,
        [historyFileSelectDropdown, systemPromptTxt, history, chatbot],
        [saveFileName, systemPromptTxt, history, chatbot],
        show_progress=True,
    )
    downloadFile.change(
        load_chat_history,
        [downloadFile, systemPromptTxt, history, chatbot],
        [saveFileName, systemPromptTxt, history, chatbot],
    )

    # Advanced
    default_btn.click(
        reset_default, [], [apiurlTxt, proxyTxt, status_display], show_progress=True
    )
    changeAPIURLBtn.click(
        change_api_url,
        [apiurlTxt],
        [status_display],
        show_progress=True,
    )
    changeProxyBtn.click(
        change_proxy,
        [proxyTxt],
        [status_display],
        show_progress=True,
    )

logging.info(
    colorama.Back.GREEN
    + "\nå·è™çš„æ¸©é¦¨æç¤ºï¼šè®¿é—® http://localhost:7860 æŸ¥çœ‹ç•Œé¢"
    + colorama.Style.RESET_ALL
)
# é»˜è®¤å¼€å¯æœ¬åœ°æœåŠ¡å™¨ï¼Œé»˜è®¤å¯ä»¥ç›´æ¥ä»IPè®¿é—®ï¼Œé»˜è®¤ä¸åˆ›å»ºå…¬å¼€åˆ†äº«é“¾æ¥
demo.title = "å·è™ChatGPT ğŸš€"

if __name__ == "__main__":
    reload_javascript()
    # if running in Docker
    if dockerflag:
        if authflag:
            demo.queue(concurrency_count=CONCURRENT_COUNT).launch(
                server_name="0.0.0.0",
                server_port=7860,
                auth=(username, password),
                favicon_path="./assets/favicon.ico",
            )
        else:
            demo.queue(concurrency_count=CONCURRENT_COUNT).launch(
                server_name="0.0.0.0",
                server_port=7860,
                share=False,
                favicon_path="./assets/favicon.ico",
            )
    # if not running in Docker
    else:
        if authflag:
            demo.queue(concurrency_count=CONCURRENT_COUNT).launch(
                share=False,
                auth=(username, password),
                favicon_path="./assets/favicon.ico",
                inbrowser=True,
            )
        else:
            demo.queue(concurrency_count=CONCURRENT_COUNT).launch(
                share=False, favicon_path="./assets/favicon.ico", inbrowser=True
            )  # æ”¹ä¸º share=True å¯ä»¥åˆ›å»ºå…¬å¼€åˆ†äº«é“¾æ¥
        # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name="0.0.0.0", server_port=7860, share=False) # å¯è‡ªå®šä¹‰ç«¯å£
        # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name="0.0.0.0", server_port=7860,auth=("åœ¨è¿™é‡Œå¡«å†™ç”¨æˆ·å", "åœ¨è¿™é‡Œå¡«å†™å¯†ç ")) # å¯è®¾ç½®ç”¨æˆ·åä¸å¯†ç 
        # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(auth=("åœ¨è¿™é‡Œå¡«å†™ç”¨æˆ·å", "åœ¨è¿™é‡Œå¡«å†™å¯†ç ")) # é€‚åˆNginxåå‘ä»£ç†
